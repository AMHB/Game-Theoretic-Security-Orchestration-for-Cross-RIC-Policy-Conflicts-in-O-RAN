# ────────────────────────────────────────────────────────────────
# Cell 1 – Setup & Reproducibility
#
# 1️⃣ Import libraries (numpy/pandas/matplotlib, etc.)
# 2️⃣ Create output directory /content/Project8
# 3️⃣ Fix random seed for reproducibility
# 4️⃣ Print a confirmation banner
# ────────────────────────────────────────────────────────────────
import time
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

OUTDIR = Path("/content/Project8")
OUTDIR.mkdir(parents=True, exist_ok=True)
np.random.seed(7)

print("✅ Setup complete. Output dir:", OUTDIR)


# ────────────────────────────────────────────────────────────────
# Cell 2 – Data Models (Strategy, Player) and Helpers
#
# 1️⃣ Define SecurityStrategy and AppPlayer dataclasses
# 2️⃣ Provide normalization helpers (enc/firewall/ids/rotation → 0..1)
# 3️⃣ Keep units consistent (shorter rotation ⇒ higher normalized value)
# ────────────────────────────────────────────────────────────────
from dataclasses import dataclass, field
from typing import Dict, List

@dataclass
class SecurityStrategy:
    enc_bin: int             # 1..5
    rotation_h: float        # 4..48
    firewall: int            # 1..5
    ids_sens: int            # 1..5
    sid: int = 0             # local strategy id tag

@dataclass
class AppPlayer:
    pid: int
    kind: str                # "security" or "performance"
    alpha: float
    beta: float
    gamma: float
    strategies: List[SecurityStrategy] = field(default_factory=list)
    current_sid: int = 0     # index into strategies

# Normalizers (keep units consistent, 0..1 scales)
def norm_enc(x):  return (x - 1) / 4.0
def norm_ord(x):  return (x - 1) / 4.0
def norm_rot(h):  # shorter rotation => stronger security, higher overhead
    return (48.0 - h) / 44.0  # 4..48 -> 1..0 mapped to 1..0 then clipped 0..1


# ────────────────────────────────────────────────────────────────
# Cell 3 – Conflict Detector & Utility Calculator
#
# 1️⃣ ConflictDetector: thresholds τ_p in normalized space + penalties λ_p
# 2️⃣ UtilityCalculator: Security and Overhead sub-scores + penalty
# 3️⃣ Overall utility: α·Security − β·Overhead + γ·Penalty (Penalty ≤ 0)
# ────────────────────────────────────────────────────────────────
class ConflictDetector:
    def __init__(self, tau_enc=1.0, tau_fw=1.0, tau_ids=1.0, tau_rot_norm=0.1,
                 lam_enc=0.5, lam_fw=0.4, lam_ids=0.3, lam_rot=0.7):
        # thresholds in native units; will be applied on normalized diffs
        self.tau_enc = tau_enc / 4.0     # scale to 0..1
        self.tau_fw  = tau_fw  / 4.0
        self.tau_ids = tau_ids / 4.0
        self.tau_rot = tau_rot_norm      # already normalized
        self.lams = dict(enc=lam_enc, fw=lam_fw, ids=lam_ids, rot=lam_rot)

    def penalty_per_player(self, i, profile):
        # profile: list of SecurityStrategy (one per player)
        vals = dict(
            enc=np.array([norm_enc(s.enc_bin) for s in profile]),
            fw =np.array([norm_ord(s.firewall) for s in profile]),
            ids=np.array([norm_ord(s.ids_sens) for s in profile]),
            rot=np.array([norm_rot(s.rotation_h) for s in profile]),
        )
        tau = dict(enc=self.tau_enc, fw=self.tau_fw, ids=self.tau_ids, rot=self.tau_rot)
        pen = 0.0
        for p, arr in vals.items():
            diff = np.max(np.abs(arr - arr[i]))
            over = max(0.0, diff - tau[p])
            pen -= self.lams[p] * over  # negative penalty
        return pen

    def residual_conflicts(self, profile):
        # count parameters whose global dispersion exceeds threshold
        vals = dict(
            enc=np.array([norm_enc(s.enc_bin) for s in profile]),
            fw =np.array([norm_ord(s.firewall) for s in profile]),
            ids=np.array([norm_ord(s.ids_sens) for s in profile]),
            rot=np.array([norm_rot(s.rotation_h) for s in profile]),
        )
        tau = dict(enc=self.tau_enc, fw=self.tau_fw, ids=self.tau_ids, rot=self.tau_rot)
        count = 0
        for p, arr in vals.items():
            span = np.max(arr) - np.min(arr)
            if span > tau[p]:
                count += 1
        return count

class UtilityCalculator:
    # weights within the sub-scores (normalized by sum)
    W_SEC = dict(enc=0.7, fw=0.6, rot=0.3, ids=0.3)
    W_OHD = dict(rot=0.7, ids=0.6, enc=0.3, fw=0.2)

    def __init__(self, players, detector):
        self.players  = players
        self.detector = detector

    def security_score(self, s: SecurityStrategy):
        w = self.W_SEC
        num = (w['enc']*norm_enc(s.enc_bin) +
               w['fw'] *norm_ord(s.firewall) +
               w['rot']*norm_rot(s.rotation_h) +
               w['ids']*norm_ord(s.ids_sens))
        den = sum(w.values())
        return num/den

    def overhead_score(self, s: SecurityStrategy):
        w = self.W_OHD
        num = (w['rot']*norm_rot(s.rotation_h) +
               w['ids']*norm_ord(s.ids_sens) +
               w['enc']*norm_enc(s.enc_bin) +
               w['fw'] *norm_ord(s.firewall))
        den = sum(w.values())
        return num/den

    def utilities(self, profile):
        # profile: list of SecurityStrategy (s_i for each player i)
        U = []
        for i, pl in enumerate(self.players):
            sec = self.security_score(profile[i])
            ohd = self.overhead_score(profile[i])
            pen = self.detector.penalty_per_player(i, profile)  # <= 0
            ui  = pl.alpha*sec - pl.beta*ohd + pl.gamma*pen
            U.append(ui)
        return np.array(U)


# ────────────────────────────────────────────────────────────────
# Cell 4 – Solvers: Nash, Cooperative (log-NSW), Stackelberg
#
# 1️⃣ Nash: iterative best-response until no change or max_iter
# 2️⃣ Cooperative: coordinate ascent on Σ log(shifted utilities)
# 3️⃣ Stackelberg: scan leader actions, one-sweep follower best-responses
# ────────────────────────────────────────────────────────────────
def best_response(players, util, init_profile, max_iter=30):
    prof = list(init_profile)
    n = len(players)
    for _ in range(max_iter):
        changed = False
        for i in range(n):
            best_u, best_s = -1e9, prof[i]
            for s in players[i].strategies:
                cand = prof.copy(); cand[i] = s
                u = util.utilities(cand)[i]
                if u > best_u + 1e-12:
                    best_u, best_s = u, s
            if best_s is not prof[i]:
                prof[i] = best_s; changed = True
        if not changed:
            break
    return prof

def coop_bargain(players, util, init_profile, max_iter=30, eps=1e-3):
    prof = list(init_profile)
    n = len(players)
    # baseline to keep logs well-defined
    base = util.utilities(prof).min()
    for _ in range(max_iter):
        improved = False
        for i in range(n):
            best_val, best_s = -1e9, prof[i]
            for s in players[i].strategies:
                cand = prof.copy(); cand[i] = s
                U = util.utilities(cand)
                # maximize sum of logs of shifted utilities
                shifted = U - base + eps
                val = np.sum(np.log(np.maximum(shifted, eps)))
                if val > best_val + 1e-12:
                    best_val, best_s = val, s
            if best_s is not prof[i]:
                prof[i] = best_s; improved = True
        if not improved:
            break
    return prof

def stackelberg(players, util, leader_idx=0, max_iter_follow=20):
    # followers best-respond (one sweep) for each leader action; pick best leader action
    best_leader_val, best_profile = -1e9, None
    n = len(players)
    for sL in players[leader_idx].strategies:
        prof = [p.strategies[p.current_sid] for p in players]
        prof[leader_idx] = sL
        # one pass of follower best-responses
        for j in range(n):
            if j == leader_idx:
                continue
            best_u, best_s = -1e9, prof[j]
            for s in players[j].strategies:
                cand = prof.copy(); cand[j] = s
                u = util.utilities(cand)[j]
                if u > best_u + 1e-12:
                    best_u, best_s = u, s
            prof[j] = best_s
        uL = util.utilities(prof)[leader_idx]
        if uL > best_leader_val + 1e-12:
            best_leader_val, best_profile = uL, prof
    return best_profile


# ────────────────────────────────────────────────────────────────
# Cell 5 – Scenario Generator (menus, players, thresholds)
#
# 1️⃣ make_strategies(): security vs performance menus (5 options)
# 2️⃣ make_players(): build N players with (α,β,γ) by scenario
# 3️⃣ Configure ConflictDetector thresholds per scenario
# 4️⃣ Return (players, detector, utility)
# ────────────────────────────────────────────────────────────────
def make_strategies(kind, m=5):
    # deterministic menus to keep results reproducible
    if kind == "security":
        encs = np.clip(np.round(np.linspace(3,5,m)),1,5).astype(int)
        rots = np.linspace(4,24,m)   # shorter
        fws  = np.clip(np.round(np.linspace(3,5,m)),1,5).astype(int)
        ids  = np.clip(np.round(np.linspace(3,5,m)),1,5).astype(int)
    else:
        encs = np.clip(np.round(np.linspace(1,3,m)),1,5).astype(int)
        rots = np.linspace(24,48,m)  # longer
        fws  = np.clip(np.round(np.linspace(1,3,m)),1,5).astype(int)
        ids  = np.clip(np.round(np.linspace(1,3,m)),1,5).astype(int)
    return [SecurityStrategy(int(encs[k]), float(rots[k]), int(fws[k]), int(ids[k]), sid=k)
            for k in range(m)]

def make_players(scenario, N=10, m=5):
    players = []
    if scenario == "Security-Focused":
        sec_cnt, perf_cnt = 8, 2
        tau_rot = 2/44.0
    elif scenario == "Balanced":
        sec_cnt, perf_cnt = 5, 5
        tau_rot = 4/44.0
    else:  # Performance-Focused
        sec_cnt, perf_cnt = 2, 8
        tau_rot = 8/44.0

    # security players
    for i in range(sec_cnt):
        alpha = np.random.uniform(0.66,0.90)
        beta  = np.random.uniform(0.23,0.35)
        gamma = np.random.uniform(0.44,0.75)
        players.append(AppPlayer(pid=len(players), kind="security",
                                 alpha=alpha, beta=beta, gamma=gamma,
                                 strategies=make_strategies("security", m),
                                 current_sid=0))
    # performance players
    for i in range(perf_cnt):
        alpha = np.random.uniform(0.45,0.65)
        beta  = np.random.uniform(0.30,0.46)
        gamma = np.random.uniform(0.44,0.75)
        players.append(AppPlayer(pid=len(players), kind="performance",
                                 alpha=alpha, beta=beta, gamma=gamma,
                                 strategies=make_strategies("performance", m),
                                 current_sid=0))

    detector = ConflictDetector(tau_enc=1.0, tau_fw=1.0, tau_ids=1.0, tau_rot_norm=tau_rot)
    util     = UtilityCalculator(players, detector)
    return players, detector, util


# ────────────────────────────────────────────────────────────────
# Cell 6 – Evaluation Loop
#
# 1️⃣ For each scenario, build players and initial profile
# 2️⃣ Run Initial / Nash / Cooperative / Stackelberg
# 3️⃣ Measure Average Security and SMO Latency (ms)
# 4️⃣ Assemble tidy DataFrames for plotting (avgsec_df, latency_df)
# ────────────────────────────────────────────────────────────────
def avg_security(util, profile):
    secs = [util.security_score(s) for s in profile]
    return float(np.mean(secs))

scenarios = ["Security-Focused", "Balanced", "Performance-Focused"]
models    = ["Initial", "Nash", "Cooperative", "Stackelberg"]

avgsec_results   = {sc: [] for sc in scenarios}
latency_results  = {sc: [] for sc in scenarios}

for sc in scenarios:
    players, detector, util = make_players(sc, N=10, m=5)
    # initial profile = first strategy for each
    init_prof = [p.strategies[p.current_sid] for p in players]

    # Initial
    t0 = time.time()
    prof0 = init_prof
    lat0 = (time.time() - t0)*1000.0
    avgsec_results[sc].append(avg_security(util, prof0))
    latency_results[sc].append(lat0)

    # Nash
    t0 = time.time()
    prof_nash = best_response(players, util, init_prof, max_iter=30)
    lat_nash  = (time.time() - t0)*1000.0
    avgsec_results[sc].append(avg_security(util, prof_nash))
    latency_results[sc].append(lat_nash)

    # Cooperative
    t0 = time.time()
    prof_coop = coop_bargain(players, util, init_prof, max_iter=30)
    lat_coop  = (time.time() - t0)*1000.0
    avgsec_results[sc].append(avg_security(util, prof_coop))
    latency_results[sc].append(lat_coop)

    # Stackelberg (leader = app 0)
    t0 = time.time()
    prof_stk  = stackelberg(players, util, leader_idx=0)
    lat_stk   = (time.time() - t0)*1000.0
    avgsec_results[sc].append(avg_security(util, prof_stk))
    latency_results[sc].append(lat_stk)

# Tidy tables
avgsec_df  = pd.DataFrame(avgsec_results, index=models).reset_index().rename(columns={"index":"Model"})
latency_df = pd.DataFrame(latency_results, index=models).reset_index().rename(columns={"index":"Model"})

print("✅ Aggregated metrics")
print(avgsec_df.head(), "\n")
print(latency_df.head())


# ────────────────────────────────────────────────────────────────
# Cell 7 – Figure 1: Average Security vs. Model (3 panels)
#
# 1️⃣ 1×3 subplots for scenarios: Security-Focused, Balanced, Performance-Focused
# 2️⃣ Colored bars by model (Initial gray, Nash green, Cooperative yellow, Stackelberg pink)
# 3️⃣ Add value labels (2 decimals), rotate x-ticks
# 4️⃣ Suptitle with top margin, save PNG to OUTDIR
# ────────────────────────────────────────────────────────────────
fig, axes = plt.subplots(1, 3, figsize=(13.5, 4), dpi=200)  # no constrained_layout

# color map per model
color_map = {
    "Initial": "lightgray",
    "Nash": "green",
    "Cooperative": "yellow",
    "Stackelberg": "pink",
}

for ax, scen in zip(axes, scenarios):
    vals = avgsec_df[scen].values  # <-- use avgsec_df (from Cell 6)
    ax.bar(models, vals, color=[color_map[m] for m in models])  # colored bars
    ax.set_title(scen, fontsize=12)
    ax.set_ylabel("Average Security (0–1)")
    ax.set_ylim(0.0, min(1.0, max(vals) * 1.15 + 0.02))

    # value labels
    for i, v in enumerate(vals):
        ax.text(i, v + 0.02, f"{v:.2f}", ha="center", va="bottom", fontsize=9)

    # tidy x labels
    ax.set_xticklabels(models, rotation=20, ha="right")

# suptitle + reserved top margin to avoid overlap
fig.suptitle("Average Security vs. Model", fontsize=14)
fig.tight_layout(rect=[0, 0.03, 1, 0.99])  # reserve top for suptitle

out1 = OUTDIR / "fig1_avg_security_3panels.png"
fig.savefig(out1, bbox_inches="tight")
plt.close(fig)
print(f"✅ Saved: {out1}")


# ────────────────────────────────────────────────────────────────
# Cell 8 – Figure 2: SMO Latency vs. Model (3 panels)
#
# 1️⃣ 1×3 subplots for the same three scenarios (consistent layout)
# 2️⃣ Reuse identical color map for visual correspondence
# 3️⃣ Value labels in milliseconds; rotate x-ticks
# 4️⃣ Suptitle with margin, save PNG to OUTDIR
# ────────────────────────────────────────────────────────────────
fig, axes = plt.subplots(1, 3, figsize=(13.5, 4), dpi=200)  # no constrained_layout

# reuse the same color map to keep colors consistent across figures
color_map = {
    "Initial": "lightgray",
    "Nash": "green",
    "Cooperative": "yellow",
    "Stackelberg": "pink",
}

for ax, scen in zip(axes, scenarios):
    vals = latency_df[scen].values
    ax.bar(models, vals, color=[color_map[m] for m in models])  # colored bars
    ax.set_title(scen, fontsize=12)
    ax.set_ylabel("SMO Latency (ms)")
    ax.set_ylim(0, max(vals) * 1.25)

    # value labels
    for i, v in enumerate(vals):
        ax.text(i, v + max(vals) * 0.04, f"{int(v)}", ha="center", va="bottom", fontsize=9)

    # tidy x labels
    ax.set_xticklabels(models, rotation=20, ha="right")

# suptitle + reserved top margin to avoid overlap
fig.suptitle("SMO Latency vs. Model", fontsize=14)
fig.tight_layout(rect=[0, 0.03, 1, 0.99])  # reserve top for suptitle

out2 = OUTDIR / "fig2_smo_latency_3panels.png"
fig.savefig(out2, bbox_inches="tight")
plt.close(fig)
print(f"✅ Saved: {out2}")


# ────────────────────────────────────────────────────────────────
# Cell 9 – Quick Preview
#
# 1️⃣ Display the saved PNGs inline (if running in a notebook)
# 2️⃣ Helps visually confirm colors, labels, and layout
# ────────────────────────────────────────────────────────────────
from IPython.display import Image, display
display(Image(filename=str(OUTDIR/"fig1_avg_security_3panels.png")))
display(Image(filename=str(OUTDIR/"fig2_smo_latency_3panels.png")))
